{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5db2f48",
   "metadata": {},
   "source": [
    "# Imports, constants & common functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d95a7bb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-04T15:05:40.724965Z",
     "start_time": "2024-06-04T15:05:39.586182Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import requests\n",
    "import bs4 as bs\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f7227e0e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-04T15:23:06.655077Z",
     "start_time": "2024-06-04T15:23:06.648813Z"
    }
   },
   "outputs": [],
   "source": [
    "# Configurable constants\n",
    "CACHE_DIR = Path('./data')\n",
    "OVERWRITE_CACHE = False\n",
    "URL_FORMAT = 'https://fragment.com/username/{name}'\n",
    "STATUS_SELECTOR = '#aj_content > main > section.tm-section.tm-auction-section > div.tm-section-header > h2 > span.tm-section-header-status'\n",
    "PRICE_SELECTOR = '#aj_content > main > section.tm-section.clearfix > div.tm-table-wrap > table > tbody > tr > td:nth-child(1) > div > div'\n",
    "\n",
    "# Calculated constants\n",
    "CACHE_DIR.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754671e3",
   "metadata": {},
   "source": [
    "# Demo of cache pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "48de417d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading cached: data/names.parquet\n"
     ]
    }
   ],
   "source": [
    "names_cache_file = CACHE_DIR / 'names.parquet'\n",
    "\n",
    "if names_cache_file.is_file() and (not OVERWRITE_CACHE):\n",
    "    print(f'Reading cached: {names_cache_file}')\n",
    "    df = pd.read_parquet(names_cache_file)\n",
    "else:\n",
    "    names = ['Adam', 'Coty', 'Bob']\n",
    "    records_accumulator = list()\n",
    "    for n in names:\n",
    "        response = requests.get(URL_FORMAT.format(name=n))\n",
    "        soup = bs.BeautifulSoup(response.text, 'html')\n",
    "        status_element = soup.select_one(STATUS_SELECTOR)\n",
    "        if status_element is None:\n",
    "            print(f'No status for {n}')\n",
    "            continue\n",
    "        status_text = status_element.text\n",
    "        print(f'Status of \"{n}\":', status_text)\n",
    "        time.sleep(0.5)\n",
    "        records_accumulator.append(dict(name=n, status=status_text))\n",
    "    df = pd.DataFrame(records_accumulator)\n",
    "    print(f'Caching: {names_cache_file}')\n",
    "    df.to_parquet(names_cache_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "332592d2-f4c5-4d5d-9ebf-d46bbfafb558",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading cached: data/names_adam_bob_coty.parquet\n"
     ]
    }
   ],
   "source": [
    "names = ['Adam', 'Coty', 'Bob']\n",
    "names_ordered_and_normalised = sorted([n.lower() for n in names])\n",
    "names_str = '_'.join(names_ordered_and_normalised)\n",
    "\n",
    "names_cache_file = CACHE_DIR / f'names_{names_str}.parquet'\n",
    "\n",
    "if names_cache_file.is_file() and (not OVERWRITE_CACHE):\n",
    "    print(f'Reading cached: {names_cache_file}')\n",
    "    df = pd.read_parquet(names_cache_file)\n",
    "else:\n",
    "    records_accumulator = list()\n",
    "    for n in names:\n",
    "        response = requests.get(URL_FORMAT.format(name=n))\n",
    "        soup = bs.BeautifulSoup(response.text, 'html')\n",
    "        status_element = soup.select_one(STATUS_SELECTOR)\n",
    "        if status_element is None:\n",
    "            print(f'No status for {n}')\n",
    "            continue\n",
    "        status_text = status_element.text\n",
    "        print(f'Status of \"{n}\":', status_text)\n",
    "        time.sleep(0.5)\n",
    "        records_accumulator.append(dict(name=n, status=status_text))\n",
    "    df = pd.DataFrame(records_accumulator)\n",
    "    print(f'Caching: {names_cache_file}')\n",
    "    df.to_parquet(names_cache_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a55ae6-8cc0-415e-a45b-b85f19c0bbad",
   "metadata": {},
   "source": [
    "# Cache + hash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d1307cba-fafc-4aca-b437-3a239d1f0506",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gist https://gist.github.com/artoby/49c4d24e28a49f01728a5b4e7e53798a\n",
    "\n",
    "from typing import Any, Optional\n",
    "import hashlib\n",
    "import base64\n",
    "import json\n",
    "\n",
    "\n",
    "def get_hash_bytes(value: Any, hash_bytes=10, salt=None) -> Optional[bytes]:\n",
    "    \"\"\"\n",
    "    param hash_bytes: how many bytes to hake for the trimmed hash, 10 bytes of data -> 16 symbols string\n",
    "    \"\"\"\n",
    "    if value is None:\n",
    "        return None\n",
    "\n",
    "    if hash_bytes <= 0:\n",
    "        raise ValueError(f'Hash bytes value should be >0, but not \"{hash_bytes}\", ignoring it')\n",
    "\n",
    "    value_str = json.dumps(value, sort_keys=True)\n",
    "\n",
    "    if (salt is not None) and (salt != ''):\n",
    "        value_str = value_str + salt\n",
    "\n",
    "    s_bytes = value_str.encode('utf-8')\n",
    "    hash_result = hashlib.sha1(s_bytes)\n",
    "    bytes_taken = hash_result.digest() if hash_bytes is None else hash_result.digest()[-hash_bytes:]\n",
    "    return bytes_taken\n",
    "\n",
    "\n",
    "def get_hash(value: Any, hash_bytes=10, salt=None) -> Optional[str]:\n",
    "    bytes_taken = get_hash_bytes(value=value, hash_bytes=hash_bytes, salt=salt)\n",
    "    if bytes_taken is None:\n",
    "        return None\n",
    "\n",
    "    result = base64.b32encode(bytes_taken).decode('utf-8').rstrip('=')\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ea8a5b0e-2721-413b-9862-2fd16f09571c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'N3M4DMXOMXKBIP3I'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_hash('abc123')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "19d7e34b-e941-40f3-a9fe-ffa5631a239d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CYTZ4Z4WOFU2QY4R'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_hash('Very very very very very very very very very very very very long string')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "086757fc-b23a-4624-b607-98a01aa68a10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CYTZ4Z4WOFU2QY4R'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_hash('Very very very very very very very very very very very very long string')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "52829e76-18cb-4764-b48f-70eb021c4bfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'WZV47YMVMYPDU242'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = [1, 2, 'abc123', 'Very very very very very very very very very very very very long string']\n",
    "get_hash(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "29db983d-2758-42e8-a301-f3b6207df5a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading cached: data/names_WF343E5B6SH4EHWG.parquet\n"
     ]
    }
   ],
   "source": [
    "names = ['Adam', 'Coty', 'Bob']\n",
    "names_ordered_and_normalised = sorted([n.lower() for n in names])\n",
    "names_hash = get_hash(names_ordered_and_normalised)\n",
    "\n",
    "names_cache_file = CACHE_DIR / f'names_{names_hash}.parquet'\n",
    "\n",
    "if names_cache_file.is_file() and (not OVERWRITE_CACHE):\n",
    "    print(f'Reading cached: {names_cache_file}')\n",
    "    df = pd.read_parquet(names_cache_file)\n",
    "else:\n",
    "    records_accumulator = list()\n",
    "    for n in names:\n",
    "        response = requests.get(URL_FORMAT.format(name=n))\n",
    "        soup = bs.BeautifulSoup(response.text, 'html')\n",
    "        status_element = soup.select_one(STATUS_SELECTOR)\n",
    "        if status_element is None:\n",
    "            print(f'No status for {n}')\n",
    "            continue\n",
    "        status_text = status_element.text\n",
    "        print(f'Status of \"{n}\":', status_text)\n",
    "        time.sleep(0.5)\n",
    "        records_accumulator.append(dict(name=n, status=status_text))\n",
    "    df = pd.DataFrame(records_accumulator)\n",
    "    print(f'Caching: {names_cache_file}')\n",
    "    df.to_parquet(names_cache_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4426bad2-e149-4a18-b336-028ceb6415d9",
   "metadata": {},
   "source": [
    "# Self shutdown to release resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a84cb5f8-e3e7-4087-97a9-51d81e0d86b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "mypid = os.getpid()\n",
    "os.kill(mypid, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3386a8e4-094d-4aa6-bb25-0039df1324bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
